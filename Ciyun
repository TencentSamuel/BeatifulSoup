from lxml import etree
import requests
import time
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import jieba
from collections import Counter   #引入Counter类作词频统计
from scipy.misc import imread

f= open('D:\chartz1.txt','rb')
text =f.read().decode('utf-8')

text_jieba = [x for x in jieba.cut(text) if len(x) >= 2]
c = Counter(text_jieba)
common_c = c.most_common(120)  #统计词频出现最多的前100个词语
print(common_c)

ciyun=dict(common_c)
pic = imread('timg.jpg')

wc1= WordCloud(font_path="simhei.ttf",   # 设置字体可以显示中文
                background_color="white",       # 背景颜色
                max_words=100,                  # 词云显示的最大词数
                #mask=color_mask,                # 设置背景图片
                max_font_size=320,              # 字体最大值
                random_state=42,
                width=1000, height=860, margin=2,# 设置图片默认的大小,但是如果使用背景图片的话,                                                   # 那么保存的图片大小将会按照其大小保存,margin为词语边缘距离
                )

wc2 = wc1.generate_from_frequencies(ciyun) 
plt.imshow(wc2)
plt.axis('off')
plt.show()
